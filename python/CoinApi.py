# æ¯ç§è´§å¸æ¯å¤©çš„ä»·æ ¼èµ°åŠ¿

import requests, pandas as pd, time, random
from datetime import datetime
import os

COIN_MAP = {
    1: ("bitcoin", "BTC"),
    2: ("ethereum", "ETH"),
    3: ("tether", "USDT"),
    4: ("solana", "SOL"),
    5: ("cardano", "ADA"),
    6: ("ripple", "XRP"),
    7: ("dogecoin", "DOGE"),
    8: ("binancecoin", "BNB"),
    9: ("litecoin", "LTC"),
    10: ("avalanche-2", "AVAX")
}

DAYS = 7
frames = []

def fetch_with_retry(url, params, symbol, max_retries=5):
    """å¤„ç† HTTP429 çš„æ™ºèƒ½é‡è¯•"""
    for attempt in range(max_retries):
        try:
            r = requests.get(url, params=params, timeout=10)
        except Exception as e:
            print(f"âŒ Network error for {symbol}: {e}")
            return None

        if r.status_code == 200:
            return r

        elif r.status_code == 429:
            wait = 5 * (2 ** attempt) + random.uniform(0, 3)
            print(f"âš ï¸ HTTP 429 for {symbol}, waiting {wait:.1f}s before retry ({attempt+1}/{max_retries})...")
            time.sleep(wait)
            continue

        else:
            print(f"âš ï¸ HTTP {r.status_code} for {symbol}, skipping.")
            return None

    print(f"âŒ Failed to fetch {symbol} after {max_retries} retries.")
    return None


for coin_id, (cg_id, symbol) in COIN_MAP.items():
    print(f"ğŸ“Š Fetching {symbol} data...")
    url = f"https://api.coingecko.com/api/v3/coins/{cg_id}/market_chart"
    params = {"vs_currency": "usd", "days": DAYS}

    r = fetch_with_retry(url, params, symbol)

    if not r:
        continue

    try:
        data = r.json()
    except Exception as e:
        print(f"âš ï¸ JSON decode failed for {symbol}: {e}")
        continue

    prices = data.get("prices", [])
    if not prices:
        print(f"âš ï¸ No price data for {symbol}, skipping.")
        continue

    df = pd.DataFrame(prices, columns=["timestamp", "Price"])
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms")
    df = df.resample("1D", on="timestamp").last().reset_index()
    df["CoinID"] = coin_id
    df["Return"] = df["Price"].pct_change()
    df["IntervalType"] = "daily"
    df["MarketDate"] = df["timestamp"].dt.date
    #df["UpdatedAt"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    df = df.dropna(subset=["Return"])

    #æ¯ç§å¸ä¿å­˜åœ¨è‡ªå·±çš„csvæ–‡ä»¶é‡Œ
    folder_path = "days"
    os.makedirs(folder_path, exist_ok=True)
    file_path = f"{folder_path}/{symbol}.csv"
    # åªä¿ç•™éœ€è¦çš„åˆ—
    new_df = df[["CoinID", "Price", "Return", "IntervalType", "MarketDate"]].copy()
    # å¦‚æœæ—§æ–‡ä»¶å­˜åœ¨ï¼Œå…ˆè¯»å‡ºæ¥
    if os.path.exists(file_path):
        try:
            old_df = pd.read_csv(file_path, parse_dates=["MarketDate"])
        except Exception as e:
            print(f"âš ï¸ Failed to read {file_path}, recreating. Error: {e}")
            old_df = pd.DataFrame()
    else:
        old_df = pd.DataFrame()
    # åˆå¹¶æ—§ + æ–°
    merged = pd.concat([old_df, new_df], ignore_index=True)
    # æŒ‰ MarketDate å»é‡ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
    merged = merged.sort_values("MarketDate").drop_duplicates(subset=["MarketDate"], keep="last")
    # ä¿å­˜
    merged.to_csv(file_path, index=False)
    print(f"ğŸ“ Updated file: {file_path} ({len(new_df)} new rows)")
    # é¢å¤–åŠ ç‚¹éšæœºå»¶è¿Ÿï¼ˆ1~3ç§’ï¼‰ï¼Œæ›´åƒäººç±»è®¿é—®
    time.sleep(random.uniform(1.0, 3.0))
